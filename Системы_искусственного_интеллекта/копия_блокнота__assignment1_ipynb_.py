# -*- coding: utf-8 -*-
"""Копия блокнота "assignment1.ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KJGzoQy_ayVGgrbU4SEqTO5IqmCKGxGi

# Лабораторная работа 1

1) Классификация данных методом k ближайших соседей ( kNN)

2) Классификация данных методом опорных векторов (SVM)

3) Построение softmax-классификатора

Вариант 1: задания 1 и 2 на наборе данных CIFAR-10

Вариант 2: задания 1 и 2 на наборе данных MNIST

Вариант 3: задания 1 и 3 на наборе данных CIFAR-10

Вариант 4: задания 1 и 3 на наборе данных MNIST

Лабораторные работы можно выполнять с использованием сервиса Google Colaboratory (https://research.google.com/colaboratory/) или на локальном компьютере.

## 1. Классификация данных методом k ближайших соседей ( kNN)
"""

# Commented out IPython magic to ensure Python compatibility.
import random
import numpy as np
import matplotlib.pyplot as plt

import torch
import torchvision
from torchvision import transforms


# %matplotlib inline
plt.rcParams['figure.figsize'] = (10.0, 8.0)
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

"""1.1 Скачайте данные в соответсвии с заданием.

CIFAR-10 по ссылке https://www.cs.toronto.edu/~kriz/cifar.html
или используйте  команду !bash get_datasets.sh (google colab, local ubuntu)

MNIST
from sklearn.datasets import load_digits
digits = load_digits()
"""

from sklearn.datasets import load_digits

dataset = load_digits()
print(dataset.data.shape)

"""1.2 Выведите несколько примеров изображений из обучающей выборки для каждого класса.


"""

# Получение уникальных меток (классов)
unique_labels = np.unique(dataset.target)

# Вывод нескольких изображений для каждого класса в столбец
num_rows = 4
num_cols = len(unique_labels)

plt.figure(figsize=(10, 4))  # Размер области вывода

for i, label in enumerate(unique_labels):
    # Нахождение индексов изображений для текущего класса
    indices = np.where(dataset.target == label)[0][:4]

    # Вывод изображений для текущего класса
    for j, index in enumerate(indices):
        # Извлечение изображения
        image = dataset.images[index]

        # Создание subplot для каждого изображения
        plt.subplot(num_rows, num_cols, j * num_cols + i + 1)
        plt.imshow(image, cmap='gray')
        plt.title(f'Label: {label}')
        plt.axis('off')

# Показываем изображения
plt.tight_layout()
plt.show()

"""1.3 Разделите данные на обучающу и тестовую выборки (X_train, y_train, X_test, y_test). Преобразуйте каждое изображение в одномерный массив."""

from sklearn.model_selection import train_test_split
# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.2, random_state=42)

# Преобразование каждого изображения в одномерный массив
X_train = np.reshape(X_train, (X_train.shape[0], -1))
X_test = np.reshape(X_test, (X_test.shape[0], -1))

# Вывод размерностей новых массивов
print("Размерность X_train_flat:", X_train.shape)
print("Размерность X_test_flat:", X_test.shape)

"""1.4 Напишите реализацию классификатора в скрипте /classifiers/k_nearest_neighbor.py и обучите его на сформированной выборке."""

import scripts.classifiers as classifiers

# Создание экземпляра классификатора
classifier = classifiers.KNearestNeighbor()

# Обучение классификатора
classifier.train(X_train, y_train)

"""1.5 Выполните классификацию на тестовой выборке"""

# Прогнозирование меток классов для тестовых данных
y_pred = classifier.predict(X_test)

"""1.6 Визуализируйте матрицу расстояний для каждого изображения из тестовой выборки до изображений из обучающей выборки.

"""

# Вывод матрицы расстояний
distances = classifier.compute_distances_two_loops(X_test)
plt.imshow(distances, cmap='spring', interpolation='nearest')
plt.colorbar()
plt.xlabel('Обучающая выборка')
plt.ylabel('Тестовая выборка')
plt.title('Матрица расстояний между изображениями')
plt.show()

"""
1.7 Посчитайте долю правильно классифицированных изображений из тестовой выборки.
"""

from sklearn.metrics import accuracy_score
print(f'Доля правильно классифицированных изображений = {accuracy_score(y_test, y_pred) * 100}%')

"""1.8 Постройте график зависимости доли правильно классифицированных изображений от числа соседей, используемых при классификации."""

ks = range(1, 500)
accuracy_scores = [accuracy_score(y_test, classifier.predict(X_test, k)) for k in ks]

# Вывод графика
plt.plot(ks, accuracy_scores)
plt.title('Зависимость точности от числа соседей')
plt.xlabel('Число соседей (k)')
plt.ylabel('Точность')
plt.grid(True)
plt.show()

"""1.9 Выберите лучшее значение параметра k на основе кросс-валидации.

"""

k_best = np.argmax(np.array(accuracy_scores)) + 1
print(f'Значение k с наибольшей точностью = {k_best}')

"""
1.10 Переобучите и протестируйте классификатор с использованием выбранного значения k.

"""

# Создание экземпляра классификатора
classifier_best = classifiers.KNearestNeighbor()

# Обучение классификатора
classifier_best.train(X_train, y_train)

# Прогнозирование меток классов для тестовых данных
y_pred = classifier_best.predict(X_test, k=6)

# Оценка точности классификатора
accuracy = np.mean(y_pred == y_test)
print(f"Точность классификатора: {accuracy * 100:.2f}%")

# Выбор индекса изображения для отображения
index_to_display = np.random.randint(low=0, high=100)

# Получение истинной метки для выбранного тестового изображения
true_label = y_test[index_to_display]

# Предсказывание метки класса для выбранного тестового изображения
predicted_label = classifier_best.predict(np.array([X_test[index_to_display]]), k=k_best)

# Отображение информации
print(f"Истинная цифра в изображении: {true_label}")
print(f"Предсказанная цифра в изображении: {int(predicted_label[0])}")

# Размер области вывода
plt.figure(figsize=(4, 4))

# Отображение тестового изображения
plt.imshow(X_test[index_to_display].reshape((8, 8)), cmap='gray')
plt.title("Тестовое изображение")
plt.axis('off')
plt.show()

"""1.11 Сделайте выводы по результатам 1 части задания."""

from sklearn.model_selection import KFold

# Создание объекта KFold для разделения на 5 фолдов
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Список для хранения оценок качества модели на каждом фолде и для каждого значения k
all_scores = []

# Разделение обучающих данных на 5 фолдов
for train_index, val_index in kf.split(X_train):
    X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]
    y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]

    # Список для хранения оценок качества модели на каждом значении k для данного фолда
    scores = []

    for k in range(1, 51):  # Изменение значения k от 1 до 50
        # Создание экземпляра классификатора для текущего значения k
        classifier_ = classifiers.KNearestNeighbor()

        # Обучение классификатора
        classifier_.train(X_fold_train, y_fold_train)

        # Прогнозирование меток классов для валидационных данных с текущим значением k
        y_pred = classifier_.predict(X_fold_val, k=k)

        # Оценка точности классификатора
        accuracy = accuracy_score(y_fold_val, y_pred)
        scores.append(accuracy)

    # Добавление списка оценок для текущего фолда в общий список
    all_scores.append(scores)

# Нахождение наилучшего значения k для каждого фолда
best_ks = np.argmax(np.array(all_scores), axis=1)  # Берем индекс максимальной оценки

# Средняя точность по всем частям
mean_accuracy = np.mean(all_scores)
print(f'Средняя точность по всем частям: {mean_accuracy * 100:.2f}')

# Среднее оптимальное значение k по всем частям
mean_best_k = np.mean(best_ks) + 1  # +1 из-за коррекции индекса
print(f'Среднее оптимальное значение k по всем частям: {mean_best_k:.2f}')

"""Выбор более маленького k может привести к высокой вариативности, когда небольшие изменения в данных могут сильно повлиять на предсказания. Большое k может привести к низкой вариативности, когда модель может недостаточно чувствительно реагировать на различия в данных из-за усреднения большого числа соседей.

## 2.  Классификация данных методом опорных векторов (SVM)

2.1 Разделите данные на обучающую, тестовую и валидационную выборки (X_train, y_train, X_test, y_test, X_val, y_val). Создайте также небольшую выборку из обучающей, на которой будет проверяться правильность работы кода (X_dev, y_dev). Преобразуйте каждое изображение в одномерный массив. Выведите размеры выборок.
"""

import tensorflow as tf
from sklearn.model_selection import train_test_split

# Загрузка данных MNIST
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Разделение данных на обучающую, тестовую и валидационную выборки
train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)
train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2

# Преобразование изображений в одномерные массивы
X_train = train_images.reshape((train_images.shape[0], -1)).astype('float32')
X_val = val_images.reshape((val_images.shape[0], -1)).astype('float32')
X_test = test_images.reshape((test_images.shape[0], -1)).astype('float32')
y_train = train_labels
y_val = val_labels
y_test = test_labels

# Создание небольшой выборки для проверки кода
X_dev, _, y_dev, _ = train_test_split(X_train, y_train, test_size=0.7, random_state=42)

# Вывод размеров выборок
print("Размер обучающей выборки:", X_train.shape, y_train.shape)
print("Размер тестовой выборки:", X_test.shape, y_test.shape)
print("Размер валидационной выборки:", X_val.shape, y_val.shape)
print("Размер небольшой выборки для проверки:", X_dev.shape, y_dev.shape)

"""2.2 Проведите предварительную обработку данных, путем вычитания среднего изображения, рассчитанного  по обучающей выборке.

2.3 Чтобы далее не учитывать смещение (свободный член b), добавьте дополнитульную размерность к массиву дынных и заполните ее 1.
"""

mean_image = np.mean(X_train, axis=0)
print(mean_image[:10])
plt.figure(figsize=(4,4))
plt.imshow(mean_image.reshape((28,28)).astype('uint8'))
plt.show()


X_train -= mean_image
X_val -= mean_image
X_test -= mean_image
X_dev -= mean_image


X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])
X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])
X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])
X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])

"""2.4 Реализуйте loss-функции в scripts/classifiers/linear_svm.py


"""

from scripts.classifiers.linear_svm import svm_loss_naive
import time

W = np.random.randn(X_train.shape[1], 10) * 0.0001

loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.000005)
print('loss: %f' % (loss, ))

"""
2.5 Убедитесь, что вы верно реализовали расчет градиента, сравнив с реализацией численными методами (код приведен ниже)."""

loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.0)

from scripts.gradient_check import grad_check_sparse
f = lambda w: svm_loss_naive(w, X_dev, y_dev, 0.0)[0]
grad_numerical = grad_check_sparse(f, W, grad)


loss, grad = svm_loss_naive(W, X_dev, y_dev, 5e1)
f = lambda w: svm_loss_naive(w, X_dev, y_dev, 5e1)[0]
grad_numerical = grad_check_sparse(f, W, grad)

"""2.6 Сравните svm_loss_naive и svm_loss_vectorized реализации"""

from scripts.classifiers.linear_svm import svm_loss_vectorized

tic = time.time()
_, grad_naive = svm_loss_naive(W, X_dev, y_dev, 0.000005)
toc = time.time()
print('Naive loss and gradient: computed in %fs' % (toc - tic))

tic = time.time()
_, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, 0.000005)
toc = time.time()
print('Vectorized loss and gradient: computed in %fs' % (toc - tic))

difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')
print('difference: %f' % difference)

"""2.7 Реализуйте стохастический градиентный спуск в /classifiers/linear_classifier.py . Реализуйте методы train() и predict() и запустите следующий код"""

from scripts.classifiers import LinearSVM
svm = LinearSVM()
tic = time.time()
loss_hist = svm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,
                      num_iters=1500, verbose=True)
toc = time.time()
print('That took %fs' % (toc - tic))

y_train_pred = svm.predict(X_train)
print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))
y_val_pred = svm.predict(X_val)
print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))

"""2.8 С помощью кросс-валидации выберите значения параметров скорости обучения и регуляризации. В кросс-валидации используйте обучающую и валидационную выборки. Оцените accuracy на тестовой выборке."""

learning_rates = [1e-7, 5e-5]
regularization_strengths = [2.5e4, 5e4]

results = {}
best_val = -1   # Лучщая точность
best_svm = None # Объект LinearSVM, достигший самой высокой скорости проверки.

for lr in learning_rates:
  for rs in regularization_strengths:
    svm = LinearSVM()
    loss_hist = svm.train(X_train, y_train, learning_rate=lr, reg=rs,
                          num_iters=2000, verbose=False)

    y_train_pred = svm.predict(X_train)
    training_accuracy = np.mean(y_train == y_train_pred)

    y_val_pred = svm.predict(X_val)
    validation_accuracy = np.mean(y_val == y_val_pred)

    results[(lr, rs)] = (training_accuracy, validation_accuracy)

    if validation_accuracy > best_val:
      best_val = validation_accuracy
      best_svm = svm

for lr, reg in sorted(results):
    train_accuracy, val_accuracy = results[(lr, reg)]
    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (
                lr, reg, train_accuracy, val_accuracy))

print('Лучшая accuracy, достигнутая во время кросс-валидации: %f' % best_val)

"""2.9 Сделайте выводы по второй части задания"""

y_test_pred = best_svm.predict(X_test)
validation_accuracy_t = np.mean(y_test == y_test_pred)
print('Лучшая accuracy, достигнутая во время кросс-валидации на тестовом наборе: %f' % validation_accuracy_t)

"""## 3.  Построение softmax-классификатора

3.1 Разделите данные на обучающую, тестовую и валидационную выборки (X_train, y_train, X_test, y_test, X_val, y_val). Создайте также небольшую выборку из обучающей, на которой будет проверяться правильность работы кода (X_dev, y_dev). Преобразуйте каждое изображение в одномерный массив. Выведите размеры выборок.
"""



"""3.2 Проведите предварительную обработку данных, путем вычитания среднего изображения, рассчитанного  по обучающей выборке.

3.3 Чтобы далее не учитывать смещение (свободный член b), добавьте дополнитульную размерность к массиву данных и заполните ее единицами.
"""

mean_image = np.mean(X_train, axis=0)
print(mean_image[:10])
plt.figure(figsize=(4,4))
plt.imshow(mean_image.reshape((32,32,3)).astype('uint8'))
plt.show()


X_train -= mean_image
X_val -= mean_image
X_test -= mean_image
X_dev -= mean_image


X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])
X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])
X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])
X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])


print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)

"""3.4 Реализуйте функции в classifiers/softmax.py



"""

from scripts.classifiers.softmax import softmax_loss_naive
import time

# Generate a random softmax weight matrix and use it to compute the loss.
W = np.random.randn(X_train.shape[1], 10) * 0.0001
loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)

# As a rough sanity check, our loss should be something close to -log(0.1).
print('loss: %f' % loss)
print('sanity check: %f' % (-np.log(0.1)))

"""3.5 Убедитесь, что вы верно реализовали расчет градиента, сравнив с реализацией численными методами (код приведен ниже)."""

loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)


from scripts.gradient_check import grad_check_sparse
f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]
grad_numerical = grad_check_sparse(f, W, grad, 10)


loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)
f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]
grad_numerical = grad_check_sparse(f, W, grad, 10)

"""3.6 Сравните softmax_loss_naive и softmax_loss_vectorized реализации"""

tic = time.time()
loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)
toc = time.time()
print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))

from scripts.classifiers.softmax import softmax_loss_vectorized
tic = time.time()
loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)
toc = time.time()
print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))


grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')
print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))
print('Gradient difference: %f' % grad_difference)

"""3.7 Реализуйте стохастический градиентный спуск в /classifiers/linear_classifier.py . Реализуйте методы train() и predict() и запустите следующий код"""

from scripts.classifiers import Softmax
sm = Softmax()
tic = time.time()
loss_hist = sm.train(X_train, y_train, learning_rate=1e-7, reg=2.5e4,
                      num_iters=1500, verbose=True)
toc = time.time()
print('That took %fs' % (toc - tic))

y_train_pred = sm.predict(X_train)
print('training accuracy: %f' % (np.mean(y_train == y_train_pred), ))
y_val_pred = sm.predict(X_val)
print('validation accuracy: %f' % (np.mean(y_val == y_val_pred), ))

"""3.8 С помощью кросс-валидации выберите значения параметров скорости обучения и регуляризации. В кросс-валидации используйте обучающую и валидационную выборки. Оцените accuracy на тестовой выборке."""

learning_rates = [1e-7, 5e-5]
regularization_strengths = [2.5e4, 5e4]

"""3.9 Сделайте выводы по третьей части задания"""

